{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skeletons and information to exercise sheet II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Load the data\n",
    "\n",
    "This is where the data will be loaded into the session.\n",
    "Pandas has a lot of useful functions for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract the features and target variable from the dataframe. \n",
    "The containing features are\n",
    "\n",
    " - 'number_of_ads', \n",
    " - 'linkration', \n",
    " - 'numberOfListItems', \n",
    " - 'FractionInput', \n",
    " - 'input'\n",
    " \n",
    "and the target variable \"sell\". \n",
    "\n",
    "We consider the example as positive example if it falls into the category \"mainly\" and negative otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Feature scaling\n",
    "\n",
    "\n",
    "The extracted features can vary vastly in range and distribution. This can be difficult for the algorithm to handle. We define a function that rescale the features into a common range.\n",
    "The video below has some insights on that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(\"https://www.youtube.com/embed/r5E2X1JdHAU\", 640, 380)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_function(x: np.array) -> np.array:\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Implement an evaluation metric \n",
    " \n",
    "To keep track of the performance of our model, we need some kind of evaluation metric (for example accuracy or true missclassification error). During training we can check periodically, if the effectiveness of our model improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(truth: np.array, prediction: np.array) -> float:\n",
    "    return 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Implement a   linear Classifier\n",
    "\n",
    "Now we want to implement a classifier. The hypothesis for the linear model is:\n",
    "\n",
    "$$ y(\\mathbf{x}) = \\mathbf{w}^T\\mathbf{x} $$\n",
    "\n",
    "This hypothesis' values range from $\\text{-}\\infty$ to $\\infty$ (in theory). We predict a class by using the sign of the output.\n",
    "\n",
    "$$ \\tilde{y}(\\mathbf{x}) = \\operatorname{sgn}(y(\\mathbf{x})) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the RSS cost function and the LMS algorithm for regression and estimation of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) Logistic Regression\n",
    "\n",
    "Now onto the more complex logistic regression.\n",
    "The logistic regression's hypothesis is:\n",
    "$$ \\large y(\\mathbf{x}) = \\frac{1}{1+\\exp(-\\mathbf{w}^T\\mathbf{x})}$$\n",
    "This function has a range of values from 0 to 1 and can be interpreted as a probility of seeing the label $c(\\mathbf{x})$ given the input $y(\\mathbf{x})\\hat{=} p(c(\\mathbf{x})=1|\\mathbf{x};w)$. \n",
    "Predictions can be made  by applying a threshold. For example if \n",
    "$$\\tilde{y}(\\mathbf{x}_i) = \\begin{cases} 1 &\\text{if } p(c(\\mathbf{x}_i=1|\\mathbf{x}_i;w) > 0.5\\\\ 0 & \\text{otherwise} \\end{cases}$$. \n",
    "\n",
    "This is analogous to the prediction method for the linear regression, which is basically the threshold 0.\n",
    "\n",
    "\n",
    "Now keep in mind that the logistic regression is in fact very similar to the linear regression algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(\"https://webis.de/downloads/lecturenotes/machine-learning/unit-en-logistic-regression.pdf#algorithm-batch-gradient-descent-logistic-loss\", 400, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: One key difference is, since the logistic regression is meant to model a probability distribution the value range of the output is to be [0,1], and so the values of y have to be 0 and 1 (in contrast to the -1 and 1 of the linear regression above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) Evaluation\n",
    "\n",
    "To find out which of the models is better suited to fit the data and especially to predict on new and unseen data, we have to make a somewhat fair comparison.\n",
    "\n",
    "Consider n-fold cross validation: For that we split our data into 5 batches, then estimate our parameters on 4 of the splits and testing on the one left out. We repeat this process for every split and estimate average performance.\n",
    "\n",
    "We provide you with a batching function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_batch_indices(n, k=5):\n",
    "    \"\"\"This function takes a range n and a number of splits k and returns k arrays of n/k integers. \n",
    "    You can use these to index an array with n elements.\"\"\"\n",
    "    assert k < n, \"Fewer samples than splits is not allowed\"\n",
    "    indices = np.array(range(n))\n",
    "    np.random.shuffle(indices)\n",
    "    return np.array_split(indices, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useful for extracting the same rows out of multiple arrays:\n",
    "```python\n",
    "indices = return_batch_indices(x.shape[0], 5)\n",
    "x[indices[0]], y[indices[0]]\n",
    "```\n",
    "will extract the same rows from x and y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this we can implement a crossvalidation function and evaluate our algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus \n",
    "\n",
    "Predicting on the test data set by applying what we have learned. Chose a hypothesis, estimate the weights and make predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_json(\"test_data_prediction_XXX.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
